# Coleta Spark Hive

AutomaÃ§Ã£o de coleta e atualizaÃ§Ã£o de dados no Hive com PySpark.

Este script realiza a extraÃ§Ã£o, limpeza e mesclagem de coletas diÃ¡rias de mÃºltiplas visÃµes Hive, consolidando-as em tabelas finais versionadas. Ideal para pipelines de Data Lake e projetos de Data Quality.

## ğŸš€ Tecnologias Utilizadas

- Python 3.x
- Apache Spark (PySpark)
- Hive (HiveWarehouseConnector)
- HDFS

## ğŸ“‚ Estrutura do Processo

1. Inicializa ambientes Spark, Hive e HDFS.
2. Para cada coleta definida:
   - Remove tabelas auxiliares anteriores.
   - Cria nova tabela com dados do dia.
   - Mescla com dados histÃ³ricos, evitando duplicaÃ§Ãµes.
   - Atualiza a tabela final.
3. Gera logs detalhados com marcaÃ§Ã£o de tempo e seÃ§Ãµes.

## ğŸ“¦ PrÃ©-requisitos

- Spark com HiveWarehouseConnector configurado
- Hive acessÃ­vel via JDBC
- PermissÃµes de escrita em HDFS e banco Hive
- Ambiente Hadoop configurado

## ğŸ§¾ Exemplo de Coleta

```python
coletas = [
    ('Clientes Ativos', 'vw_clientes_ativos', 'tb_clientes'),
    ('Produtos Vendidos', 'vw_produtos_vendidos', 'tb_produtos')
]
